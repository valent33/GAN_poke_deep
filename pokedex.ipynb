{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import plotly.express as px\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'images/final/'\n",
    "width = 128\n",
    "height = 128\n",
    "channels = 4\n",
    "image_size = (width, height)\n",
    "input_shape = (width, height, channels)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels):\n",
    "    fig = px.imshow(images, width=width, height=height)\n",
    "    fig.update_layout(\n",
    "        title=f\"Label: {labels}\",\n",
    "        width=300,\n",
    "        height=300,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_images(ds, n):\n",
    "    for image, label in ds.take(1):\n",
    "        for i in range(n):\n",
    "            print(image[i][0][0])\n",
    "            print(image[i].shape)\n",
    "            plot_images(image[i], class_names[int(tf.argmax(tf.reshape(label[i], [-1, 1]), axis=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13894 files belonging to 905 classes.\n",
      "Using 11116 files for training.\n",
      "Using 2778 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=image_size,\n",
    "    crop_to_aspect_ratio=True,\n",
    "    interpolation=\"bilinear\",\n",
    "    color_mode=\"rgba\",\n",
    "    shuffle=True,\n",
    "    seed=905,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n",
      "(128, 128, 4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x: %{x}<br>y: %{y}<extra></extra>",
         "name": "0",
         "source": "data:image/png;base64,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",
         "type": "image",
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 300,
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Label: Zangoose"
        },
        "width": 300,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_n_images(train_ds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_and_rotate = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1, fill_mode=\"constant\"),\n",
    "    # tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # print(image.shape)\n",
    "    alpha_channel = image[:, :, :, 3]\n",
    "    rgb_channels = image[:, :, :, :3]\n",
    "    alpha_bool = alpha_channel > 0\n",
    "    alpha_bool = tf.expand_dims(alpha_bool, axis=-1)\n",
    "    # print(alpha_bool.shape)\n",
    "    # print(rgb_channels.shape)\n",
    "    rgb_channels = tf.where(alpha_bool, rgb_channels, 0)\n",
    "    \n",
    "    # Normalize the pixel values to be between 0 and 1\n",
    "    image = preprocess_input(rgb_channels)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "    ds = ds.map(lambda x, y: (preprocess_image(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Use data augmentation only on the training set\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (flip_and_rotate(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Use buffered prefecting on all datasets\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "\n",
    "    # ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "\n",
    "channels = 3\n",
    "input_shape = (width, height, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_images(train_ds, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"tf.cond_1\" (type TFOpLambda).\n\nTo be compatible with tf.function, Python functions must return zero or more Tensors or ExtensionTypes or None values; in compilation of <function <lambda> at 0x00000271F34A7C70>, found return value of type KerasTensor, which is not a Tensor or ExtensionType.\n\nCall arguments received by layer \"tf.cond_1\" (type TFOpLambda):\n  • pred=tf.Tensor(shape=(), dtype=bool)\n  • true_fn=<function <lambda> at 0x00000271F34A7C70>\n  • false_fn=<function <lambda> at 0x00000271F34A7B50>\n  • name=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\GAN_poke\\pokedex.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GAN_poke/pokedex.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Preprocess the inputs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GAN_poke/pokedex.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m channels \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GAN_poke/pokedex.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# Convert the image to RGB and remove the alpha channel\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GAN_poke/pokedex.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcond(tf\u001b[39m.\u001b[39;49mequal(tf\u001b[39m.\u001b[39;49mshape(inputs)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39m4\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GAN_poke/pokedex.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                 \u001b[39mlambda\u001b[39;49;00m: inputs[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, :\u001b[39m3\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GAN_poke/pokedex.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                 \u001b[39mlambda\u001b[39;49;00m: inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GAN_poke/pokedex.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Convert the image to float32\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GAN_poke/pokedex.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(x, tf\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py:119\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[1;34m(self, op, args, kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m    116\u001b[0m     \u001b[39misinstance\u001b[39m(x, keras_tensor\u001b[39m.\u001b[39mKerasTensor)\n\u001b[0;32m    117\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten([args, kwargs])\n\u001b[0;32m    118\u001b[0m ):\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m TFOpLambda(op)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    120\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[1;32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer \"tf.cond_1\" (type TFOpLambda).\n\nTo be compatible with tf.function, Python functions must return zero or more Tensors or ExtensionTypes or None values; in compilation of <function <lambda> at 0x00000271F34A7C70>, found return value of type KerasTensor, which is not a Tensor or ExtensionType.\n\nCall arguments received by layer \"tf.cond_1\" (type TFOpLambda):\n  • pred=tf.Tensor(shape=(), dtype=bool)\n  • true_fn=<function <lambda> at 0x00000271F34A7C70>\n  • false_fn=<function <lambda> at 0x00000271F34A7B50>\n  • name=None"
     ]
    }
   ],
   "source": [
    "# Define the EfficientNetB4 model\n",
    "base_model = EfficientNetB4(include_top=False, input_shape=(width, height, 3), pooling='avg', weights='imagenet')\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Define the model inputs\n",
    "inputs = tf.keras.Input(shape=(width, height, 4), batch_size=batch_size)\n",
    "\n",
    "# Preprocess the inputs\n",
    "if channels == 4:\n",
    "    # Convert the image to RGB and remove the alpha channel\n",
    "    x = tf.cond(tf.equal(tf.shape(inputs)[-1], 4),\n",
    "                lambda: inputs[..., :3],\n",
    "                lambda: inputs)\n",
    "\n",
    "    # Convert the image to float32\n",
    "    x = tf.cast(x, tf.float32)\n",
    "\n",
    "    # Replace black pixels with white pixels\n",
    "    mask = tf.reduce_all(tf.equal(x, [0, 0, 0]), axis=-1)\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "    x = tf.where(mask, tf.ones_like(x), x)\n",
    "else:\n",
    "    x = inputs\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs, x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(32, 128, 128, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 1792)             17673823  \n",
      "                                                                 \n",
      " dense (Dense)               (32, 512)                 918016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (32, 512)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32, 256)                 131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (32, 256)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (32, 905)                 232585    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,955,752\n",
      "Trainable params: 1,281,929\n",
      "Non-trainable params: 17,673,823\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(None, 128, 128, 4)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\GAN_poke\\pokedex.ipynb Cell 12\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GAN_poke/pokedex.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_ds, validation_data\u001b[39m=\u001b[39;49mval_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filece_aidmu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(None, 128, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "837c519a48be08d8749c778cb72b9b5aac116a087aa5d1d99ee0359dceff73e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
