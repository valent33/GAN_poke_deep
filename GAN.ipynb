{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import plotly.express as px\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'images/final/'\n",
    "width = 128\n",
    "height = 128\n",
    "channels = 4\n",
    "image_size = (width, height)\n",
    "input_shape = (width, height, channels)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, class_names = load_data(directory, batch_size, image_size, GAN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare(train_ds, shuffle=True, augment=True, GAN=True)\n",
    "\n",
    "channels = 3\n",
    "input_shape = (width, height, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_batch, label_batch in train_ds.take(1):\n",
    "#     print(image_batch[0][50][50])\n",
    "#     im = image_batch * 127.5 + 127.5\n",
    "#     print(im[0][50][50])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_images(train_ds, 5, class_names, GAN=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator model\n",
    "def define_discriminator(in_shape=input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    # normal\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # downsample to 64x64\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # downsample to 32x32\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # downsample to 16x16\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # downsample to 8x8\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # classifier\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    # foundation for 8x8 feature maps\n",
    "    n_nodes = 256 * 8 * 8\n",
    "    model.add(tf.keras.layers.Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Reshape((8, 8, 256)))\n",
    "    # upsample to 16x16\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(256, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # upsample to 32x32\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(256, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # upsample to 64x64\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # upsample to 128x128\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # output layer\n",
    "    model.add(tf.keras.layers.Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # connect them\n",
    "    model = tf.keras.Sequential()\n",
    "    # add generator\n",
    "    model.add(g_model)\n",
    "    # add the discriminator\n",
    "    model.add(d_model)\n",
    "    # compile model\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 128)     3584      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 16385     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,200,385\n",
      "Trainable params: 1,200,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build and compile the discriminator\n",
    "discriminator = define_discriminator()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 16384)             1654784   \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 16384)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 256)      1048832   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      1048832   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 128)      524416    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 128, 128, 128)    262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 3)       3459      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,542,595\n",
      "Trainable params: 4,542,595\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the generator\n",
    "generator = define_generator(100)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_2 (Sequential)   (None, 128, 128, 3)       4542595   \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 1200385   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,742,980\n",
      "Trainable params: 4,542,595\n",
      "Non-trainable params: 1,200,385\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "gan_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = g_model.predict(x_input)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = tf.zeros((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = tf.random.normal(shape=(n_samples, latent_dim))\n",
    "    return x_input\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    X = []\n",
    "    while len(X) < n_samples:\n",
    "        dataset.shuffle(100, seed=123)\n",
    "        for x, _ in dataset.take(5):\n",
    "            for i in range(len(x)):\n",
    "                X.append(x[i])\n",
    "                if len(X) == n_samples:\n",
    "                    break\n",
    "            if len(X) == n_samples:\n",
    "                break\n",
    "    X = tf.stack(X)\n",
    "    y = tf.ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "    # prepare real samples\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    # summarize discriminator performance\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    # save plot\n",
    "    save_plot(x_fake, epoch)\n",
    "    # save the generator model tile file\n",
    "    filename = 'generator_model_e%03d.h5' % (epoch+1)\n",
    "    g_model.save(filename)\n",
    "\n",
    "def save_plot(examples, epoch, n=10):\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64):\n",
    "    bat_per_epo = int(dataset.cardinality())\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # enumerate batches over the training set\n",
    "        for j, batch in enumerate(dataset):\n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = batch[0], batch[1]\n",
    "            half_batch = int(X_real.shape[0])\n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # create training set for the discriminator\n",
    "            y_real = tf.reshape(y_real, (half_batch, 1))\n",
    "            X, y = tf.concat([X_real, X_fake], axis=0), tf.concat([y_real, y_fake], axis=0)\n",
    "            # update discriminator model weights\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            # prepare points in latent space as input for the generator\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = tf.ones((n_batch, 1))\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            # summarize loss on this batch\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "        # evaluate the model performance, sometimes\n",
    "        if (i) % 100 == 0:\n",
    "            summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "    # save the generator model\n",
    "    g_model.save('generator_model_final.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# train model\n",
    "# train(generator, discriminator, gan_model, train_ds, latent_dim, n_epochs=150)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('generator_model_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x: %{x}<br>y: %{y}<extra></extra>",
         "name": "0",
         "source": "data:image/png;base64,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",
         "type": "image",
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "align": "left",
          "bgcolor": "#ff7f0e",
          "bordercolor": "#c7c7c7",
          "borderpad": 2,
          "borderwidth": 1,
          "font": {
           "color": "#ffffff",
           "family": "Courier New, monospace",
           "size": 12
          },
          "opacity": 0.8,
          "showarrow": false,
          "text": "real: 22%",
          "x": 1,
          "xref": "paper",
          "y": 1,
          "yref": "paper"
         }
        ],
        "height": 350,
        "images": [
         {
          "layer": "below",
          "sizex": 0.3,
          "sizey": 0.3,
          "source": "images/final/real/1.png",
          "x": 1,
          "xref": "paper",
          "y": 1.1,
          "yref": "paper"
         }
        ],
        "margin": {
         "l": 0,
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "black",
           "width": 2
          },
          "type": "rect",
          "x0": 0,
          "x1": 128,
          "xref": "x",
          "y0": 0,
          "y1": 128,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Label: image générée"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "showgrid": false,
         "showticklabels": false,
         "visible": false,
         "zeroline": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "showgrid": false,
         "showticklabels": false,
         "visible": false,
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = model.predict(generate_latent_points(100, 1))\n",
    "plot_image(X[0], \"image générée\", {\"real\": float(discriminator.predict(X))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 67ms/step\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_7/conv2d_10/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\enzoh\\AppData\\Local\\Temp\\ipykernel_2276\\3494988752.py\", line 7, in <module>\n      plot_image(X[i], \"image générée\", {\"real\":argmax(discriminator.predict(X[i])) })\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential_7/conv2d_10/Conv2D'\ninput must be 4-dimensional[32,64,3]\n\t [[{{node sequential_7/conv2d_10/Conv2D}}]] [Op:__inference_predict_function_6927165]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m#show the 10 most confident predictions of the discriminator\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     plot_image(X[i], \u001b[39m\"\u001b[39m\u001b[39mimage générée\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mreal\u001b[39m\u001b[39m\"\u001b[39m:argmax(discriminator\u001b[39m.\u001b[39;49mpredict(X[i])) })\n",
      "File \u001b[1;32mc:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_7/conv2d_10/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\enzoh\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\enzoh\\AppData\\Local\\Temp\\ipykernel_2276\\3494988752.py\", line 7, in <module>\n      plot_image(X[i], \"image générée\", {\"real\":argmax(discriminator.predict(X[i])) })\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential_7/conv2d_10/Conv2D'\ninput must be 4-dimensional[32,64,3]\n\t [[{{node sequential_7/conv2d_10/Conv2D}}]] [Op:__inference_predict_function_6927165]"
     ]
    }
   ],
   "source": [
    "X = model.predict(generate_latent_points(100, 100))\n",
    "#show the 10 most confident predictions of the discriminator\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN only fire \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with Pokemon attributes\n",
    "pokemon_data = pd.read_csv(\"PokeDataset.csv\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_type(type,size=(128,128),directory=\"images/final\"):\n",
    "    # Get the names of all Pokemon that have \"Fire\" as their Type1 or Type2 attribute\n",
    "    pokemon_names = set(pokemon_data[(pokemon_data['Type1'] == type) | (pokemon_data['Type2'] == type)]['Name'])\n",
    "    # Filter train_ds to only include images of Pokemon that have \"Fire\" as either their Type1 or Type2 attribute\n",
    "\n",
    "    # iterate trough folder images\\final\\ and put in a numpy array image in folder that are in water_pokemon_names\n",
    "\n",
    "\n",
    "    # initialize an empty numpy array to store the images\n",
    "    num_images = 0\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for name in dirs:\n",
    "            if name in pokemon_names:\n",
    "                num_images += len(os.listdir(os.path.join(subdir, name)))\n",
    "    images = np.empty((num_images, size[0], size[1], 4), dtype=np.float32)\n",
    "\n",
    "    i = 0\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        # iterate through all subdirectories but only keep the ones that are in water_pokemon_names\n",
    "        for name in dirs:\n",
    "            if name in pokemon_names:\n",
    "                # iterate through all images in the subdirectory\n",
    "                for file in os.listdir(os.path.join(subdir, name)):\n",
    "                    # open the image and resize it\n",
    "                    img = Image.open(os.path.join(subdir, name, file))\n",
    "                    img = img.resize(size)\n",
    "                    # convert the image to RGBA\n",
    "                    img = img.convert('RGBA')\n",
    "                    # convert the image to a numpy array\n",
    "                    img = np.array(img)\n",
    "                    # add the image to the numpy array\n",
    "                    images[i] = img\n",
    "                    i += 1\n",
    "    return images,num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "images_size = (128, 128)\n",
    "num_images = 0\n",
    "directory = \"images/final/\"\n",
    "\n",
    "\n",
    "# Get the names of all Pokemon that have \"Fire\" as their Type1 or Type2 attribute\n",
    "water_pokemon_names = set(pokemon_data[(pokemon_data['Type1'] == 'Water') | (pokemon_data['Type2'] == 'Water')]['Name'])\n",
    "\n",
    "# Filter train_ds to only include images of Pokemon that have \"Fire\" as either their Type1 or Type2 attribute\n",
    "\n",
    "# iterate trough folder images\\final\\ and put in a numpy array image in folder that are in water_pokemon_names\n",
    "\n",
    "\n",
    "# initialize an empty numpy array to store the images\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    for name in dirs:\n",
    "        if name in water_pokemon_names:\n",
    "            num_images += len(os.listdir(os.path.join(subdir, name)))\n",
    "images = np.empty((num_images, images_size[0], images_size[1], 4), dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    # iterate through all subdirectories but only keep the ones that are in water_pokemon_names\n",
    "    for name in dirs:\n",
    "        if name in water_pokemon_names:\n",
    "            # iterate through all images in the subdirectory\n",
    "            for file in os.listdir(os.path.join(subdir, name)):\n",
    "                # open the image and resize it\n",
    "                img = Image.open(os.path.join(subdir, name, file))\n",
    "                img = img.resize(images_size)\n",
    "                # convert the image to RGBA\n",
    "                img = img.convert('RGBA')\n",
    "                # convert the image to a numpy array\n",
    "                img = np.array(img)\n",
    "                # add the image to the numpy array\n",
    "                images[i] = img\n",
    "                i += 1\n",
    "\n",
    "water_labels = tf.ones((num_images,1))\n",
    "water_ds = tf.data.Dataset.from_tensor_slices((images, water_labels))\n",
    "water_ds = water_ds.batch(64)\n",
    "water_ds = prepare(water_ds,shuffle=True, augment=True, GAN=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_discriminator = define_discriminator()\n",
    "water_generator = define_generator(100)\n",
    "water_gan_model = define_gan(water_generator, water_discriminator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/device:GPU:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     train(water_generator, water_discriminator, water_gan_model, water_ds, \u001b[39m100\u001b[39m, n_epochs\u001b[39m=\u001b[39m\u001b[39m101\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    train(water_generator, water_discriminator, water_gan_model, water_ds, 100, n_epochs=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# load model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39mgenerator_model_e1001.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = tf.keras.models.load_model('generator_model_e1001.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# generate images\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(generate_latent_points(\u001b[39m100\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m      3\u001b[0m plot_image(X[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mimage générée\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# generate images\n",
    "X = model.predict(generate_latent_points(100, 1))\n",
    "plot_image(X[0], \"image générée\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91d527cafe2f425a4290ffff6183ccc7232b7b1c0c079161faf3c53f7523f56f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
